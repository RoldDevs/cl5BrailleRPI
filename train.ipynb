{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN Model for Text Validation\n",
    "\n",
    "This notebook trains a CNN model to validate text recognized by easyOCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from cnn_validator import BrailleValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'\n",
    "\n",
    "# Check if dataset exists\n",
    "if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
    "    print(\"Error: Dataset directories not found.\")\n",
    "else:\n",
    "    print(\"Dataset found. Proceeding with training...\")\n",
    "    \n",
    "# Count samples in each class\n",
    "classes = sorted(os.listdir(train_dir))\n",
    "class_counts = {}\n",
    "\n",
    "for cls in classes:\n",
    "    class_path = os.path.join(train_dir, cls)\n",
    "    if os.path.isdir(class_path):\n",
    "        count = len(os.listdir(class_path))\n",
    "        class_counts[cls] = count\n",
    "        \n",
    "print(f\"Found {len(class_counts)} classes with {sum(class_counts.values())} total training samples\")\n",
    "\n",
    "# Display class distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.title('Number of Training Samples per Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom data generator for the split data\n",
    "class CustomDataGenerator:\n",
    "    def __init__(self, image_paths, labels, batch_size=32, target_size=(64, 64), augment=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.augment = augment\n",
    "        self.n_samples = len(image_paths)\n",
    "        self.indices = np.arange(self.n_samples)\n",
    "        self.current_idx = 0\n",
    "        np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_samples / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.current_idx = 0\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = np.zeros((len(batch_indices), *self.target_size, 1))\n",
    "        batch_y = np.zeros(len(batch_indices))\n",
    "        \n",
    "        for i, idx in enumerate(batch_indices):\n",
    "            img_path = self.image_paths[idx]\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read {img_path}\")\n",
    "                img = np.zeros(self.target_size)\n",
    "            else:\n",
    "                img = cv2.resize(img, self.target_size)\n",
    "            \n",
    "            # Apply augmentation if needed\n",
    "            if self.augment:\n",
    "                # Random rotation\n",
    "                if np.random.rand() > 0.5:\n",
    "                    angle = np.random.uniform(-10, 10)\n",
    "                    M = cv2.getRotationMatrix2D((self.target_size[0]//2, self.target_size[1]//2), angle, 1)\n",
    "                    img = cv2.warpAffine(img, M, self.target_size)\n",
    "                \n",
    "                # Random shift\n",
    "                if np.random.rand() > 0.5:\n",
    "                    tx = np.random.uniform(-3, 3)\n",
    "                    ty = np.random.uniform(-3, 3)\n",
    "                    M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "                    img = cv2.warpAffine(img, M, self.target_size)\n",
    "                \n",
    "                # Random zoom\n",
    "                if np.random.rand() > 0.5:\n",
    "                    scale = np.random.uniform(0.9, 1.1)\n",
    "                    M = cv2.getRotationMatrix2D((self.target_size[0]//2, self.target_size[1]//2), 0, scale)\n",
    "                    img = cv2.warpAffine(img, M, self.target_size)\n",
    "            \n",
    "            # Normalize and add channel dimension\n",
    "            img = img.astype('float32') / 255.0\n",
    "            batch_x[i] = img.reshape(*self.target_size, 1)\n",
    "            batch_y[i] = self.labels[idx]\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def next(self):\n",
    "        if self.current_idx >= len(self):\n",
    "            self.on_epoch_end()\n",
    "        \n",
    "        batch = self.__getitem__(self.current_idx)\n",
    "        self.current_idx += 1\n",
    "        return batch\n",
    "\n",
    "# Create data generators\n",
    "train_generator = CustomDataGenerator(train_images, train_labels, batch_size=32, augment=True)\n",
    "val_generator = CustomDataGenerator(val_images, val_labels, batch_size=32, augment=False)\n",
    "\n",
    "# Create validator instance\n",
    "validator = BrailleValidator()\n",
    "\n",
    "# Set training parameters\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "# Train the model with custom generators\n",
    "model = validator.build_model()\n",
    "\n",
    "# Create callbacks\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'braille_cnn_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator.next,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator.next,\n",
    "    validation_steps=len(val_generator),\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "validator.model = model\n",
    "validator.save_model('braille_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = 'braille_cnn_model.h5'\n",
    "validator.save_model(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Model with Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from braille_utils import magic_filter_bw\n",
    "\n",
    "def test_with_sample(image_path):\n",
    "    # Load and preprocess image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Could not load image {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Convert to grayscale if needed\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    processed = magic_filter_bw(gray)\n",
    "    \n",
    "    # Display original and processed images\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(processed, cmap='gray')\n",
    "    plt.title('Processed Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Test with a few sample characters from the image\n",
    "    # This is just a simplified example - in practice, you would segment characters first\n",
    "    # For demonstration, we'll just resize the whole image and predict\n",
    "    resized = cv2.resize(processed, (64, 64))\n",
    "    prediction, confidence = validator.predict(resized)\n",
    "    \n",
    "    print(f\"Predicted character: {prediction}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample images from the test set\n",
    "# You can replace these with actual paths to test images\n",
    "sample_images = [\n",
    "    'dataset/test/A/sample1.jpg',\n",
    "    'dataset/test/B/sample1.jpg',\n",
    "    'dataset/test/C/sample1.jpg'\n",
    "]\n",
    "\n",
    "for img_path in sample_images:\n",
    "    if os.path.exists(img_path):\n",
    "        print(f\"Testing with {img_path}\")\n",
    "        test_with_sample(img_path)\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Image not found: {img_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
